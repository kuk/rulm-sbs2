{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca94b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "dotenv = dict(read_dotenv('.env'))\n",
    "openai.api_key = dotenv['OPENAI_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab73c4",
   "metadata": {},
   "source": [
    "# label studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d247a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "label_client = label_studio_sdk.Client('http://localhost:8080', dotenv['LABELSTUDIO_TOKEN'])\n",
    "label_client.check_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32069add",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_projects = {\n",
    "    _.title: _\n",
    "    for _ in label_client.list_projects()\n",
    "}\n",
    "translate_project = title_projects['translate']\n",
    "classify_project = title_projects['classify']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede36217",
   "metadata": {},
   "source": [
    "# sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a44e90d",
   "metadata": {},
   "source": [
    "## alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16dabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/alpaca\n",
    "!curl -L https://github.com/yizhongw/self-instruct/raw/main/human_eval/user_oriented_instructions.jsonl \\\n",
    "    > data/sources/alpaca/user_oriented_instructions.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fca385",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = read_jsonl('data/sources/alpaca/user_oriented_instructions.jsonl')\n",
    "alpaca_items = list(parse_alpaca(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa473e",
   "metadata": {},
   "source": [
    "## vicuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16051ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/vicuna\n",
    "!curl -L https://github.com/lm-sys/vicuna-blog-eval/raw/main/eval/table/question.jsonl \\\n",
    "    > data/sources/vicuna/question.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bffdeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = read_jsonl('data/sources/vicuna/question.jsonl')\n",
    "vicuna_items = list(parse_vicuna(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b97d2c4",
   "metadata": {},
   "source": [
    "## arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/arena\n",
    "!curl -L curl -L https://huggingface.co/datasets/lmsys/chatbot_arena_conversations/resolve/main/data/train-00000-of-00001-cced8514c7ed782a.parquet \\\n",
    "    > data/sources/arena/train-00000-of-00001-cced8514c7ed782a.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88246d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "records = pd.read_parquet('data/sources/arena/train-00000-of-00001-cced8514c7ed782a.parquet').itertuples()\n",
    "arena_items = list(parse_arena(records))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c177f80",
   "metadata": {},
   "source": [
    "# orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42507178",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_items = alpaca_items + vicuna_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f73172",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_items = {\n",
    "    _['instruction']: _\n",
    "    for _ in arena_items\n",
    "    if _['lang'] == 'English'\n",
    "}\n",
    "orig_items.extend(random.sample(list(instruction_items.values()), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "672928a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json('data/orig.json', orig_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62b37138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'c189117c-b2a1-4ac9-9f0e-06370cfe8b6b',\n",
       "  'source': 'arena',\n",
       "  'source_id': 'adccaf90b7904fdeb56a1da9150c2492',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'Let\\'s think about writing a Python script step by step. \\n\\n1) Analyze and define the use case. What does the script need to accomplish? \\n\\n2) Analyze the required parameters? What does it need to know? How can it get the parameters? \\n\\n3) Define functions for use cases.\\n\\n4) Execute the script if it is running as the main module.\\n\\nHere is an example script for saving a message to a file:\\n\\nimport os\\n\\ndef get_user_input():\\n    message = input(\"Please enter your message: \")\\n    file_name = input(\"Please enter the file name: \")\\n    return message, file_name\\n\\ndef save_message_to_file(message, file_name):\\n    with open(file_name, \\'w\\') as file:\\n        file.write(message)\\n    print(f\"Message saved to {file_name}\")\\n\\ndef main():\\n    message, file_name = get_user_input()\\n    save_message_to_file(message, file_name)\\n\\nif __name__ == \"__main__\":\\n    main()\\n\\nWrite a python script for a user to append a message to a file.'},\n",
       " {'id': '6eaa90f6-e2d7-484b-8dfe-88848d982b50',\n",
       "  'source': 'arena',\n",
       "  'source_id': '30d0d8edd3694eea9ecb6cc56242e9b3',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'I have two quarters and a ball. I place the ball in a cup, and place the cup in my room. I  take the quarters and place them in my kitchen. Now I take the cup and place it next to the quarters. I put the quarters in the cup. Where is the cup, and how many items are in it?'},\n",
       " {'id': '2bed8861-0338-4b20-822a-4c33e0b723f2',\n",
       "  'source': 'alpaca',\n",
       "  'source_id': 'user_oriented_task_201',\n",
       "  'instruction': 'Provide a name for the dish given the ingredients and instructions.\\n\\n\"INGREDIENTS:\\n2 (5 oz) cans Bumble Bee® Solid White Albacore Tuna, drained\\n1 avocado\\n2 Tbsp Sriracha\\n1 Tbsp Dijon mustard\\n2 to 3 Tbsp celery, chopped\\n2 Tbsp red onion, chopped\\n2 green onions, chopped\\n1 Tbsp fresh cilantro, chopped\\nSalt and pepper, to taste\\n2 heaping cups leafy green lettuce\\n1 cup matchstick carrots\\n4 (10 inch) whole wheat tortillas\\nINSTRUCTIONS:\\nIn a medium bowl, mash together tuna and avocado until combined. Add in the rest of the ingredients through the salt and pepper, mixing well.\\nTo assemble, top each tortilla with a 1/2 cup leafy greens, 1/4 cup matchstick carrots and divide the tuna mixture evenly among the wraps. Tightly roll up the tortilla, slice and enjoy!\"'},\n",
       " {'id': 'b36935fb-5edc-4be1-a8ba-135bce07ed59',\n",
       "  'source': 'arena',\n",
       "  'source_id': 'f583dd3a24e24ef9834a1ac2904a6370',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'what is the average airspeed velocity of an unladen swallow?'},\n",
       " {'id': 'd5e8b30b-5488-4d29-a4b4-b374ae251702',\n",
       "  'source': 'alpaca',\n",
       "  'source_id': 'user_oriented_task_69',\n",
       "  'instruction': 'Find the answer that best describes the underlined SAT word. Select the correct option and explain the meaning of the underlined word.\\n\\n\"Despite the _cacophony, the student tried to study. \\nA. Loud sounds\\nB. Difficult subject\\nC. Late hour\\nD. Low lighting\"'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_items = read_json('data/orig.json')\n",
    "random.sample(orig_items, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de570a92",
   "metadata": {},
   "source": [
    "# tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_items = read_json('data/tasks.json')\n",
    "id_task_items = {_['id']: _ for _ in task_items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_items.extend(\n",
    "    {\n",
    "        'id': _['id'],\n",
    "        'source': _['source'],\n",
    "        'instruction': None,\n",
    "        'category': None\n",
    "    }\n",
    "    for _ in orig_items\n",
    "    if _['source'] == 'arena'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json('data/tasks.json', task_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2079d8",
   "metadata": {},
   "source": [
    "# translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce657dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_items = [\n",
    "    {\n",
    "        'id': _['id'],\n",
    "        'instruction': _['instruction'],\n",
    "        'answer': None\n",
    "    }\n",
    "    for _ in orig_items\n",
    "    if _['source'] == 'arena'\n",
    "]\n",
    "id_translate_items = {_['id']: _ for _ in translate_items}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a5971f",
   "metadata": {},
   "source": [
    "## auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27096d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in translate_items if not _['answer']]\n",
    "queue = iter(tqdm(items))\n",
    "workers = [openai_translate_worker(queue) for _ in range(10)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50978c8",
   "metadata": {},
   "source": [
    "## review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_items = [\n",
    "    translate_label_item(_)\n",
    "    for _ in translate_items\n",
    "    if not id_task_items[_['id']]['instruction']\n",
    "]\n",
    "random.choice(label_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af21e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_project.delete_all_tasks();\n",
    "translate_project.import_tasks(label_items);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5763565",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_item in translate_project.export_tasks():\n",
    "    item = label_translate_item(label_item)\n",
    "    id_task_items[item['id']]['instruction'] = item['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cfb55e",
   "metadata": {},
   "source": [
    "# classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6213074",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_items = [\n",
    "    {\n",
    "        'id': item['id'],\n",
    "        'instruction': item['instruction'],\n",
    "        'category': item['category'],\n",
    "        'max_sim': None\n",
    "    }\n",
    "    for _ in task_items\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c80b14",
   "metadata": {},
   "source": [
    "## auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263316d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_embeddings = read_pickle('data/embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [\n",
    "    _ for _ in classify_items\n",
    "    if _['id'] not in id_embeddings\n",
    "]\n",
    "for index in tqdm(range(0, len(items), 64)):\n",
    "    batch = items[index:index + 64]\n",
    "    texts = [_['instruction'] for _ in batch]\n",
    "    embeddings = openai_embed_batch(texts)\n",
    "    for item, embedding in zip(batch, embeddings):\n",
    "        id_embeddings[item['id']] = np.array(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ca588",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle('data/embeddings.pkl', id_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24754a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_items = [\n",
    "    _ for _ in classify_items\n",
    "    if _['category'] and _['category'] != 'bad instruction'\n",
    "]\n",
    "items = [_ for _ in classify_items if not _['category']]\n",
    "\n",
    "for item in tqdm(items):\n",
    "    max_sim = 0\n",
    "    for target_item in target_items:\n",
    "        sim = cosine_sim(\n",
    "            id_embeddings[item['id']],\n",
    "            id_embeddings[target_item['id']]\n",
    "        )\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            item['category'] = target_item['category']\n",
    "    item['max_sim'] = max_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7a7f2",
   "metadata": {},
   "source": [
    "## review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320535ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "for item in classify_items:\n",
    "    if not item['max_sim']:\n",
    "        continue\n",
    "        \n",
    "    if item['category'] != 'enumerate':\n",
    "        continue\n",
    "        \n",
    "    items.append(item)\n",
    "\n",
    "items = sorted(items, key=lambda _: _['max_sim'], reverse=False)\n",
    "label_items = [classify_label_item(_) for _ in items]\n",
    "\n",
    "print('|label_items| =', len(label_items))\n",
    "random.choice(label_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_project.delete_all_tasks();\n",
    "classify_project.import_tasks(label_items);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "for label_item in classify_project.export_tasks():\n",
    "    item = label_classify_item(label_item)\n",
    "    id_task_items[item['id']] = item['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110788d",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40127d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "infer_items = read_json('data/infer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e693ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_items.extend(\n",
    "    {\n",
    "        'id': _['id'],\n",
    "        'model': 'yagpt_chat',\n",
    "        'instruction': _['instruction'],\n",
    "        'answer': None\n",
    "    }\n",
    "    for _ in task_items\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json('data/infer.json', infer_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e4c13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "items = [\n",
    "    _ for _ in infer_items\n",
    "    if _['model'] == 'yagpt_chat'\n",
    "    if _['answer'] is not None\n",
    "]\n",
    "print('|items| =', len(items))\n",
    "\n",
    "# random.shuffle(items)\n",
    "for item in items[-10:]:\n",
    "    if item['answer']:\n",
    "        print(item['instruction'])\n",
    "        print('----')\n",
    "        print(item['answer'])\n",
    "        print('---\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c13ddd",
   "metadata": {},
   "source": [
    "## turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'turbo_2']\n",
    "queue = iter(tqdm(items))\n",
    "workers = [openai_infer_worker(queue, model='gpt-3.5-turbo-0613') for _ in range(20)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc58a7c",
   "metadata": {},
   "source": [
    "## gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3ec45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'gpt4_2']\n",
    "queue = iter(tqdm(items))\n",
    "workers = [openai_infer_worker(queue, model='gpt-4-0613', request_timeout=1200) for _ in range(20)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52431698",
   "metadata": {},
   "source": [
    "## gigachat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "headers = dict(read_headers('.gigachat'))\n",
    "gigachat_client = gigachat_client_init(headers)\n",
    "\n",
    "# After ~5 min / 260 answers blocked for ~1 hour\n",
    "# {'result': 'rejected', 'reason': 'UserBlocked', 'user_blocked_until': '2023-08-25T11:00:24+00:00'}\n",
    "\n",
    "# \"в полуавтоматическом режиме банят, если 3 временных бана, то могут опять решить забанить насовсем.\n",
    "# Так что при временном бане лучше какое-то время  подождать.\"\n",
    "\n",
    "# \"из-за запросов типа \"Люди умирают, когда их убивают, откуда это высказывание?\". Цензор такое\n",
    "# отлавливает сколько-то раз и во временный бан отправляет\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'gigachat']\n",
    "queue = iter(tqdm(items[:100]))\n",
    "workers = [gigachat_infer_worker(gigachat_client, queue) for _ in range(2)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad626baf",
   "metadata": {},
   "source": [
    "## yagpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a970ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = !~/yandex-cloud/bin/yc iam create-token\n",
    "YAGPT_TOKEN = lines[0]\n",
    "\n",
    "lines = !~/yandex-cloud/bin/yc resource-manager folder get --name default --format json\n",
    "data = json.loads(''.join(lines))\n",
    "YAGPT_FOLDER_ID = data['id']\n",
    "\n",
    "# token expires every ~12 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df587c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "yagpt_client = yagpt_client_init(YAGPT_TOKEN, YAGPT_FOLDER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1471595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'yagpt_instruct']\n",
    "queue = iter(tqdm(items))\n",
    "limiter = Limiter(min_delay=1.2)\n",
    "workers = [yagpt_infer_worker(yagpt_client, limiter, queue, mode='instruct') for _ in range(5)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a879bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'yagpt_chat']\n",
    "queue = iter(tqdm(items))\n",
    "limiter = Limiter(min_delay=1.2)\n",
    "workers = [yagpt_infer_worker(yagpt_client, limiter, queue, mode='chat') for _ in range(5)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4376c",
   "metadata": {},
   "source": [
    "# sbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d03908",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "orig_items = read_json('data/orig.json')\n",
    "task_items = read_json('data/tasks.json')\n",
    "infer_items = read_json('data/infer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a069ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref_items = read_json('pref.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8951631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt3.5-turbo\n",
    "# saiga2_7b\n",
    "# saiga2_13b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c6e1463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = Counter()\n",
    "\n",
    "# instruction_answers = defaultdict(dict)\n",
    "# for item in pref_items:\n",
    "#     left_model, right_model = item['left_model'], item['right_model']\n",
    "#     left_answer, right_answer = item['left_answer'], item['right_answer']\n",
    "    \n",
    "#     if right_model == 'gpt3.5-turbo':\n",
    "#         left_model, right_model = right_model, left_model\n",
    "#         left_answer, right_answer = right_answer, left_answer\n",
    "        \n",
    "#     if left_model != 'gpt3.5-turbo':\n",
    "#         continue\n",
    "        \n",
    "#     if right_model != 'saiga2_7b':\n",
    "#         continue\n",
    "        \n",
    "#     instruction_answers[item['instruction']] = right_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e2c41e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# items = []\n",
    "# for item in task_items:\n",
    "#     if item['source'] == 'vicuna':\n",
    "#         instruction = item['instruction']\n",
    "#     elif item['source'] == 'alpaca':\n",
    "#         instruction = item['instruction']\n",
    "#         index = instruction.find('\\n\\n\"')\n",
    "#         if index > 0:\n",
    "#             instruction = instruction[:index]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c437ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "text = requests.get('https://github.com/IlyaGusev/rulm/raw/master/self_instruct/data/user_v2_saiga2_7b_answers.jsonl').text\n",
    "alpaca_answer_items = [json.loads(_) for _ in text.splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c015248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('https://github.com/IlyaGusev/rulm/raw/master/self_instruct/data/vicuna_saiga2_7b_answers.jsonl').text\n",
    "vicuna_answer_items = [json.loads(_) for _ in text.splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ab1ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_items = alpaca_answer_items + vicuna_answer_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f50cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_id_ids = {_['source_id']: _['id'] for _ in orig_items if _['source'] in ('alpaca', 'vicuna')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3540a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_instructions = {_['id']: _['instruction'] for _ in task_items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c052702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a5019e07-7568-4327-b182-1b956be00b34\n"
     ]
    }
   ],
   "source": [
    "items = []\n",
    "for item in answer_items:\n",
    "    id = source_id_ids[item['id']]\n",
    "    if id not in id_instructions:\n",
    "        print(id, file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    instruction = id_instructions[id]\n",
    "    items.append({\n",
    "        'id': id,\n",
    "        'model': 'saiga2_7b',\n",
    "        'instruction': instruction,\n",
    "        'answer': item['answer']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b03ca50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for item in items:\n",
    "#     print(item['instruction'])\n",
    "#     print('---\\n')\n",
    "#     print(item['answer'])\n",
    "#     print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7273ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_items.extend(items)\n",
    "write_json('data/infer.json', infer_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680db4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6219e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0049260a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7c76ae0",
   "metadata": {},
   "source": [
    "# show samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6749f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "source_items = defaultdict(list)\n",
    "for item in task_items:\n",
    "    source_items[item['source']].append(item)\n",
    "\n",
    "with open('data/tasks.md', 'w') as file:\n",
    "    with redirect_stdout(file):\n",
    "        for source in ['alpaca', 'vicuna', 'arena']:\n",
    "            print(f'<h1>{source}</h1>')\n",
    "\n",
    "            items = [_ for _ in source_items[source] if _['category']]\n",
    "            for item in random.sample(items, 30):\n",
    "                category = item['category']\n",
    "                print(f'<code>#{category}</code>')\n",
    "                print('<br/>')\n",
    "                instruction = html.escape(item['instruction'])\n",
    "                print('<br/>\\n'.join(instruction.splitlines()))\n",
    "                print('<br/><br/>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rulm-sbs2",
   "language": "python",
   "name": "rulm-sbs2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
